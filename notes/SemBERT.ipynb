{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN_conv1d\n",
    "\n",
    "<div>\n",
    "<img src='imgs/subwords.png' width='600' height='600'/>\n",
    "</div>\n",
    "\n",
    "-----------\n",
    "\n",
    "<div>\n",
    "<img src='imgs/conv1.png' width='600' height='6500'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "目的是将一组subword的表征变成一个表征，维度保持不变\n",
    "\"\"\"\n",
    "\n",
    "class CNN_conv1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_conv1d, self).__init__()\n",
    "        self.char_dim = 10\n",
    "        self.filter_size = 3\n",
    "        self.out_channels = 10\n",
    "        self.char_cnn =nn.Conv1d(in_channels=self.char_dim, out_channels=self.out_channels, kernel_size=self.filter_size)  #输出维度不变\n",
    "        # in_channels(int) – 输入信号的通道。在文本分类中，即为词向量的维度\n",
    "        # out_channels(int) – 卷积产生的通道（生成向量维度）。有多少个out_channels，就需要多少个1维卷积。这里，我们为了保持维度统一，使用与char_dim相同的。\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            inputs: [bs,max_len, max_word_len, dim]\n",
    "        \"\"\"\n",
    "        \n",
    "        bsz, word_len, max_word_len, dim = inputs.size()\n",
    "\n",
    "        inputs = inputs.view(-1, max_word_len, dim) \n",
    "        x = inputs.transpose(1, 2)  # 一维卷积是在最后一维上扫，需要将dim放到倒数第二维的位置\n",
    "        print(x.size())\n",
    "        x = self.char_cnn(x)\n",
    "        print(x.size())\n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool1d(x, kernel_size=x.size(-1))  # 最后一维计算maxpooling, 保证表征维度不变\n",
    "        print(x.size())\n",
    "        x = self.dropout(x.squeeze())\n",
    "        out = x.view(bsz, word_len, -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# [bs, max_len, max_word_len, dim]\n",
    "cnn_bert = torch.rand(4, 15, 7, 10)\n",
    "max_word_len = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN_conv1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 10, 7])\n",
      "torch.Size([60, 10, 5])\n",
      "torch.Size([60, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "out = cnn(cnn_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 15, 10])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TagEmebedding\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src='imgs/tag-emb.png' width='500' height='500'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "目的是对tag映射成向量，tag序列映射到数据矩阵\n",
    "\"\"\"\n",
    "\n",
    "class TagEmbeddings(nn.Module):\n",
    "    \"\"\"Simple tag embeddings, randomly initialized.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TagEmbeddings, self).__init__()\n",
    "        self.tag_embeddings = nn.Embedding(config.tag_vocab_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.dropout_prob)\n",
    "\n",
    "    def forward(self, input_tag_ids):\n",
    "        tags_embeddings = self.tag_embeddings(input_tag_ids)\n",
    "        embeddings = tags_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "    \n",
    "class TagEmebedding(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TagEmebedding, self).__init__()\n",
    "        # Embedding\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.embed = TagEmbeddings(config)\n",
    "        # Linear\n",
    "        self.fc = nn.Linear(config.hidden_size, config.output_dim)\n",
    "        #  dropout\n",
    "        self.dropout = nn.Dropout(config.dropout_prob)\n",
    "\n",
    "    def forward(self, flat_input_ids, num_aspect):  \n",
    "        # flat_input_ids.size() = (batch_size*num_aspect, seq_len)\n",
    "        embed = self.embed(flat_input_ids) # (batch_size*num_aspect, seq_len， dim)\n",
    "        embed = self.dropout(embed)\n",
    "        input = embed.view(-1, num_aspect, flat_input_ids.size(1), self.hidden_size)\n",
    "        # linear\n",
    "        logit = self.fc(input) # 最后一维\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 tag_vocab_size,\n",
    "                 hidden_size=5,\n",
    "                 layer_num=1,\n",
    "                 output_dim=5,\n",
    "                 dropout_prob=0.1,\n",
    "                 num_aspect=4\n",
    "                 ):\n",
    "        self.tag_vocab_size = tag_vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.output_dim = output_dim\n",
    "        self.num_aspect = num_aspect\n",
    "        \n",
    "tag_config = Config(tag_vocab_size=50,\n",
    "                       hidden_size=10,\n",
    "                       layer_num=1,\n",
    "                       output_dim=10,\n",
    "                       dropout_prob=0.1,\n",
    "                       num_aspect=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_model = TagEmebedding(tag_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机初始化一个batch_size=8,num_aspect=3（SRL序列最大数量），tag_seq_len=15的序列\n",
    "flat_input_tag_ids = torch.randint(0, 49, (24, 15))\n",
    "num_aspect = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32, 41, 28, 25, 19, 40, 14, 11, 32,  4, 45, 12, 46, 36, 22],\n",
       "        [26, 28, 21, 11, 38, 36, 10, 48,  2, 38, 23, 38,  7, 16, 42],\n",
       "        [ 4, 14, 31, 25, 19, 43, 38, 32, 15, 23, 42, 16, 14, 41, 21],\n",
       "        [12, 19, 40, 40, 28,  9, 28, 19, 37, 23, 17, 38,  7, 42, 26],\n",
       "        [36, 28, 42,  9, 26, 25, 33, 16, 39, 37,  1,  8, 47, 39, 36],\n",
       "        [19, 33,  5, 19, 13, 28,  4, 30,  5,  9, 25, 43, 30, 39, 48],\n",
       "        [36, 44, 29,  3, 15, 28,  7, 22, 22,  7, 16, 17,  8, 17,  9],\n",
       "        [19,  6, 13, 39, 30, 17,  7, 38, 45, 47, 22,  7, 15, 36, 31],\n",
       "        [ 5,  3, 15,  2,  5, 14, 41, 17,  2, 13, 37,  9, 16,  7,  7],\n",
       "        [ 7,  8, 38, 30,  1,  3, 38, 32, 46, 45, 30, 40, 10, 13, 14],\n",
       "        [44, 23, 17, 34, 29,  8,  6, 24, 25,  0,  3,  8, 10, 24, 16],\n",
       "        [ 5, 30, 19,  7,  5, 37, 47, 36, 39, 27,  8, 22, 16, 44,  0],\n",
       "        [20, 45,  3, 47, 17, 42, 38, 11, 36, 10, 19, 17,  7, 48, 19],\n",
       "        [ 3, 37, 48,  1, 10, 45, 11, 23,  4, 15, 13, 35,  1,  1, 47],\n",
       "        [ 5, 13, 40,  5, 21, 26, 44, 27, 17, 46, 42, 32, 41, 10, 15],\n",
       "        [11, 29, 19, 23,  7, 32, 23, 26, 32, 40,  6, 42,  7, 25, 11],\n",
       "        [17, 28, 29,  6, 16, 20, 28, 34, 36, 38, 33,  9, 41,  8, 11],\n",
       "        [ 5, 39, 26, 31, 41,  5, 24, 28,  3, 28, 29, 22, 19, 30,  9],\n",
       "        [32, 20,  4, 26,  7, 32, 25, 20,  8,  9,  7, 33, 20, 17, 14],\n",
       "        [39, 35, 25, 19, 19, 19,  2, 15, 29, 18, 20,  2, 13,  7, 10],\n",
       "        [47, 36, 34, 37, 19, 14, 43, 31, 26, 29,  9, 16,  9, 47, 23],\n",
       "        [31, 12, 44, 47, 15, 10,  8, 26,  1,  3, 44, 18, 21,  8, 41],\n",
       "        [40, 23, 40, 41, 35, 35, 25,  7, 28, 16, 34, 31, 38,  0, 17],\n",
       "        [19, 28, 11, 39, 39, 20, 25,  6, 23, 46, 47,  3, 33,  7, 41]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_input_tag_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 15])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_input_tag_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_output = tag_model(flat_input_tag_ids, num_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 15, 10])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiGRU\n",
    "\n",
    "<div>\n",
    "<img src='imgs/bigru.png' width='500' height='500'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "目的是对tag_embedding使用BiGRU编码\n",
    "额外增加自递归模型，来在表示之中融入时序关系\n",
    "\"\"\"\n",
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BiGRU, self).__init__()\n",
    "        # Embedding\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.embed = TagEmbeddings(config)\n",
    "        # GRU\n",
    "        self.bigru = nn.GRU(config.hidden_size, config.hidden_size, dropout=config.dropout_prob,\n",
    "                            num_layers=config.layer_num,\n",
    "                            bidirectional=True, batch_first=True)\n",
    "        # input_size：输入数据X的特征值的数目\n",
    "        # hidden_size：隐藏层的神经元数量，也就是隐藏层的特征数量。\n",
    "        # batch_first：如果设置为 True，则输入数据的维度中第一个维度就 是 batch 值，默认为 False。\n",
    "        #              默认情况下第一个维度是序列的长度， 第二个维度才是 - - batch，第三个维度是特征数目。\n",
    "        \n",
    "        # Linear\n",
    "        self.fc = nn.Linear(config.hidden_size * 2, config.output_dim)\n",
    "        #  dropout\n",
    "        self.dropout = nn.Dropout(config.dropout_prob)\n",
    "\n",
    "    def forward(self, flat_input_ids, embed, num_aspect):  \n",
    "        # flat_input_ids.size() = (batch_size*num_aspect, seq_len)\n",
    "        input = embed.view(flat_input_ids.size(0), embed.size(2), -1)   # 铺平，[bs*num_aspect, seq_len, dim]\n",
    "        self.bigru.flatten_parameters() # 重置参数的数据指针，提升内存的利用率和效率\n",
    "        # gru\n",
    "        gru_out, _ = self.bigru(input)  # 每个时刻的输出，[bs*num_aspect, max_len, 2*dim]\n",
    "        gru_out = gru_out.view(-1, num_aspect, flat_input_ids.size(1), 2 * self.hidden_size)    # [bs,num_aspect, max_len, 2*dim]\n",
    "        logit = self.fc(gru_out)    # 线性降维，[bs,num_aspect, max_len, dim]\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/himon/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "bigru_config = Config(tag_vocab_size=50,\n",
    "                           hidden_size=10,\n",
    "                           layer_num=1,\n",
    "                           output_dim=10,\n",
    "                           dropout_prob=0.1,\n",
    "                           num_aspect=3)\n",
    "bi_gru = BiGRU(bigru_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入tag序列：flat_input_tag_ids=[24, 15]\n",
    "# tag序列的embedding结果：tag_output=[8, 3, 15, 10]\n",
    "tag_output = bi_gru(flat_input_tag_ids, tag_output, num_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 15, 10])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
